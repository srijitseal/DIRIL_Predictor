{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b04c185-2567-4668-bd63-3b4b8d118d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from dimorphite_dl.dimorphite_dl import DimorphiteDL\n",
    "from rdkit.Chem import AddHs\n",
    "from rdkit.Chem import inchi\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from IPython.display import display\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.Chem.MolStandardize import Standardizer\n",
    "from rdkit.Chem import MolStandardize\n",
    "from collections import Counter\n",
    "\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from process_input_file import tokenizer\n",
    "from gather_metabolites import gather_preds\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import inchi\n",
    "from dimorphite_dl.dimorphite_dl import DimorphiteDL\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "# Initialize pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "\n",
    "def smiles_to_inchikey14(smiles):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to the first 14 characters of its corresponding InChIKey.\n",
    "\n",
    "    Parameters:\n",
    "    - smiles (str): A SMILES string representing a chemical compound.\n",
    "\n",
    "    Returns:\n",
    "    - str: The first 14 characters of the InChIKey corresponding to the input SMILES, or\n",
    "           an empty string if conversion is not possible.\n",
    "    \"\"\"\n",
    "    # Convert SMILES to a molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        # Convert molecule to InChI\n",
    "        inchi_val = inchi.MolToInchi(mol)\n",
    "        if inchi_val:\n",
    "            # Convert InChI to InChIKey\n",
    "            inchi_key = inchi.InchiToInchiKey(inchi_val)\n",
    "            # Return the first 14 characters of the InChIKey\n",
    "            return inchi_key[:14]\n",
    "    return \"\"\n",
    "\n",
    "def safely_protonate(x, min_ph=7, max_ph=7):\n",
    "    \n",
    "    dimorphite = DimorphiteDL(min_ph=min_ph, max_ph=max_ph, pka_precision=0)\n",
    "    \n",
    "    result = dimorphite.protonate(x)\n",
    "    # Check if result is a list and not empty\n",
    "    if isinstance(result, list) and result:\n",
    "        return result[0]  # Return first element if it's a list and has elements\n",
    "    elif result:  # If result is not a list but not None or False (assuming dimorphite.protonate might return useful non-list values)\n",
    "        return result\n",
    "    return x  # Return the original value if result is None or an empty list\n",
    "\n",
    "\n",
    "def process_dataset(df, smiles_column=\"smiles\", binary_column=\"binary_label\", min_ph=7, max_ph=7):\n",
    "    \n",
    "    # The result is a DataFrame where each cell contains another DataFrame of predictions\n",
    "    df['Standardized_SMILES'] = df[smiles_column].parallel_apply(smiles_standardiser)\n",
    "    df['Standardized_SMILES'] = df['Standardized_SMILES'].parallel_apply(check_carbon)\n",
    "    # Filter out SMILES strings that couldn't be standardized\n",
    "    filtered_data = df[df['Standardized_SMILES'] != \"Cannot_do\"]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Assuming filtered_data is your DataFrame and predict_metabolites_for_smiles is your function\n",
    "    results_series = filtered_data.apply(lambda row: predict_metabolites_for_smiles(row['Standardized_SMILES'], row[smiles_column], row[binary_column], min_ph=min_ph, max_ph=max_ph), axis=1)\n",
    "\n",
    "    # Combine the individual DataFrames into a single DataFrame\n",
    "    # This involves concatenating the DataFrames stored in each cell of the results_series\n",
    "    combined_results_df = pd.concat(results_series.values.flatten().tolist(), keys=results_series.index).reset_index(level=1, drop=True)\n",
    "    \n",
    "    return(combined_results_df)\n",
    "\n",
    "def predict_metabolites_for_smiles(smiles_std, input_smiles, label, min_ph=7, max_ph=7, beam_size=5, visualize=False):\n",
    "    \n",
    "    # Step 1: Call prepare_input_file.py to tokenize smiles\n",
    "    smiles_processed = tokenizer(smiles_std)\n",
    "    \n",
    "    # Define the output path for the predicted metabolites\n",
    "    processed_input_path = 'tmprw_xge6h_processed.csv'\n",
    "    # Open the file in write mode ('w') and write the processed SMILES string to it\n",
    "    with open(processed_input_path, 'w') as file:\n",
    "        file.write(smiles_processed)\n",
    "    \n",
    "    predicted_metabolites_file = 'tmprw_xge6h_predicted_metabolites.csv'\n",
    "\n",
    "    # Step 2: Translate the molecules into metabolites\n",
    "    # Adjust your script or method to translate molecules based on the processed input\n",
    "    # For the purpose of this example, we'll assume a script or function that can be called here.\n",
    "    # This is where you'd integrate or call your translation mechanism.\n",
    "    subprocess.run(['./translate_molecules', processed_input_path, str(beam_size), predicted_metabolites_file])\n",
    "\n",
    "    #  3: Process predictions to get a CSV file of predicted metabolites\n",
    "    # This might be redundant if your translation step already outputs a CSV; adjust as necessary.\n",
    "    predicted_metabolites_df = gather_preds(smiles_std, predicted_metabolites_file, beam_size)\n",
    "    \n",
    "    # Creating a new row with the SMILES string for both columns\n",
    "    original_smiles = pd.DataFrame({'Input_SMILES': [input_smiles], 'Input_Standardised_SMILES': [smiles_std], 'Output': [smiles_std], 'Label': [label]})\n",
    "    \n",
    "    # predicted_metabolites_df['Input_Standardised_SMILES'] = smiles_std\n",
    "    predicted_metabolites_df['Label'] = label\n",
    "    predicted_metabolites_df['Input_SMILES'] = input_smiles\n",
    "\n",
    "    # Appending the original DataFrame to the new row DataFrame\n",
    "    # The ignore_index=True option is used to reindex the new DataFrame\n",
    "    final_df = pd.concat([original_smiles, predicted_metabolites_df], ignore_index=True)\n",
    "    \n",
    "    final_df[\"protonated_Output\"] = final_df[\"Output\"].apply(lambda x: safely_protonate(x, min_ph=min_ph, max_ph=max_ph))\n",
    "    \n",
    "    final_df[\"InchiKey\"]= final_df[\"Output\"].apply(smiles_to_inchikey14)\n",
    "    final_df = final_df.drop_duplicates(subset=[\"InchiKey\"], keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def smiles_standardiser(smiles, min_ph=7, max_ph=7):\n",
    "    standardizer = Standardizer()\n",
    "    smiles_original = smiles\n",
    "\n",
    "    # Read SMILES and convert it to RDKit mol object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    " \n",
    "    try:\n",
    "        smiles_clean_counter = Counter()\n",
    "        mol_dict = {}\n",
    "        is_finalize = False\n",
    "\n",
    "        #This solved phosphate oxidation in most cases but introduces a problem for some compounds: eg. geldanamycin where the stable strcutre is returned\n",
    "        inchi_standardised = Chem.MolToInchi(mol)\n",
    "        mol = Chem.MolFromInchi(inchi_standardised)\n",
    "\n",
    "        display(Draw.MolToImage(mol))\n",
    "\n",
    "        # removeHs, disconnect metal atoms, normalize the molecule, reionize the molecule\n",
    "        mol = rdMolStandardize.Cleanup(mol) \n",
    "        # if many fragments, get the \"parent\" (the actual mol we are interested in) \n",
    "        mol = rdMolStandardize.FragmentParent(mol)\n",
    "        # try to neutralize molecule\n",
    "        uncharger = rdMolStandardize.Uncharger() # annoying, but necessary as no convenience method exists\n",
    "\n",
    "        mol = uncharger.uncharge(mol)# standardize molecules using MolVS and RDKit\n",
    "        mol = standardizer.charge_parent(mol)\n",
    "        mol = standardizer.isotope_parent(mol)\n",
    "        mol = standardizer.stereo_parent(mol)\n",
    "\n",
    "        #Normalize tautomers \n",
    "        normalizer = MolStandardize.tautomer.TautomerCanonicalizer()\n",
    "        mol = normalizer.canonicalize(mol)\n",
    "\n",
    "        #Final Rules\n",
    "        mol = standardizer.standardize(mol)\n",
    "        mol_standardized = mol\n",
    "\n",
    "        # convert mol object back to SMILES\n",
    "        smiles_standardized = Chem.MolToSmiles(mol_standardized)\n",
    "                \n",
    "        print(smiles_standardized)\n",
    "        return smiles_standardized \n",
    "    \n",
    "    except:     \n",
    "        \n",
    "        return \"Cannot_do\"\n",
    "    \n",
    "def check_carbon(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        for atom in mol.GetAtoms():\n",
    "            if atom.GetSymbol() == 'C':\n",
    "                return smiles\n",
    "    return \"Cannot_do\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff2b519-dadf-4e47-9ec1-9269c5686b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(=O)Nc1ccc(cc1)O.Cl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCC(=O)c1ccc(cc1)O.Br</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  smiles  binary_label\n",
       "0  CC(=O)Nc1ccc(cc1)O.Cl             0\n",
       "1  CCC(=O)c1ccc(cc1)O.Br             1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "# Initialize pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "# from smiles_without_borders import process_dataset\n",
    "\n",
    "# Provided data\n",
    "smiles_data = [\n",
    "    'CC(=O)Nc1ccc(cc1)O.Cl',\n",
    "    'CCC(=O)c1ccc(cc1)O.Br'\n",
    "]\n",
    "\n",
    "# Creating the DataFrame\n",
    "df_smiles = pd.DataFrame(smiles_data, columns=['smiles'])\n",
    "df_smiles\n",
    "# Adding a new column of binary labels\n",
    "# For demonstration, assigning binary labels in an alternating manner\n",
    "df_smiles['binary_label'] = [0, 1]\n",
    "\n",
    "df_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd15564-359a-4398-b3e9-04b7360092ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51330a8bb9ee46c79d3b59ec8274874e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1), Label(value='0 / 1'))), HBox(c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC(=O)Nc1ccc(O)cc1\n",
      "CCC(=O)c1ccc(O)cc1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c12d55f66344ca8a199d1a6decaa8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1), Label(value='0 / 1'))), HBox(c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SENT 1: ('C', 'C', '(', '=', 'O', ')', 'N', 'c', '1', 'c', 'c', 'c', '(', 'O', ')', 'c', 'c', '1')\n",
      "PRED 1: C C ( = O ) N c 1 c c c ( O S ( = O ) ( = O ) O ) c c 1\n",
      "PRED SCORE: -0.6941\n",
      "\n",
      "BEST HYP:\n",
      "[-0.6941] ['C', 'C', '(', '=', 'O', ')', 'N', 'c', '1', 'c', 'c', 'c', '(', 'O', 'S', '(', '=', 'O', ')', '(', '=', 'O', ')', 'O', ')', 'c', 'c', '1']\n",
      "[-1.8424] ['C', 'C', '(', '=', 'O', ')', 'N', 'c', '1', 'c', 'c', 'c', '(', 'O', 'S', '(', '=', 'O', ')', '(', '=', 'O', ')', '[O-]', ')', 'c', 'c', '1']\n",
      "[-2.3001] ['N', 'c', '1', 'c', 'c', 'c', '(', 'O', ')', 'c', 'c', '1']\n",
      "[-4.0184] ['C', 'C', '(', '=', 'O', ')', 'N', 'c', '1', 'c', 'c', 'c', '(', 'O', 'S', '(', '=', 'O', ')', '(', '=', 'O', ')', 'O', ')', 'c', '(', 'O', ')', 'c', '1']\n",
      "[-4.1129] ['C', 'C', '(', '=', 'O', ')', 'N', 'c', '1', 'c', 'c', 'c', '(', 'O', ')', 'c', '(', 'O', ')', 'c', '1']\n",
      "PRED AVG SCORE: -0.0248, PRED PPL: 1.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-seal@broadinstitut-41f01/.local/lib/python3.7/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SENT 1: ('C', 'C', '(', 'C', ')', '=', 'C', 'C', 'N', '1', 'C', 'C', 'C', '2', '(', 'C', ')', 'c', '3', 'c', 'c', '(', 'O', ')', 'c', 'c', 'c', '3', 'C', 'C', '1', 'C', '2', 'C')\n",
      "PRED 1: C C ( C ) = C C N 1 C C C 2 ( C ) c 3 c c ( O ) c ( O ) c c 3 C C 1 C 2 C\n",
      "PRED SCORE: -1.5356\n",
      "\n",
      "BEST HYP:\n",
      "[-1.5356] ['C', 'C', '(', 'C', ')', '=', 'C', 'C', 'N', '1', 'C', 'C', 'C', '2', '(', 'C', ')', 'c', '3', 'c', 'c', '(', 'O', ')', 'c', '(', 'O', ')', 'c', 'c', '3', 'C', 'C', '1', 'C', '2', 'C']\n",
      "[-2.6854] ['C', 'C', '(', 'C', ')', '=', 'C', 'C', 'N', '1', 'C', 'C', 'C', '2', '(', 'C', 'O', ')', 'c', '3', 'c', 'c', '(', 'O', ')', 'c', 'c', 'c', '3', 'C', 'C', '1', 'C', '2', 'C']\n",
      "[-2.8571] ['C', 'C', '(', 'C', ')', 'C', 'C', 'N', '1', 'C', 'C', 'C', '2', '(', 'C', ')', 'c', '3', 'c', 'c', '(', 'O', ')', 'c', 'c', 'c', '3', 'C', 'C', '1', 'C', '2', 'C']\n",
      "[-3.5262] ['C', 'C', '(', 'C', ')', '=', 'C', 'C', 'O', 'P', '(', '=', 'O', ')', '(', 'O', ')', 'O']\n",
      "[-8.5052] ['C', 'C', '(', 'C', ')', '=', 'C', 'C', 'N', '1', 'C', 'C', 'C', '2', '(', 'C', ')', 'c', '3', 'c', 'c', '(', 'O', ')', 'c', '(', 'O', ')', 'c', 'c', '3', 'C', 'C', '1', 'C', '2']\n",
      "PRED AVG SCORE: -0.0415, PRED PPL: 1.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-seal@broadinstitut-41f01/.local/lib/python3.7/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SENT 1: ('C', 'C', '(', 'C', ')', '=', 'C', 'C', 'N', '1', 'C', 'C', 'C', '2', '(', 'C', ')', 'c', '3', 'c', 'c', '(', 'O', ')', 'c', 'c', 'c', '3', 'C', 'C', '1', 'C', '2', 'C')\n",
      "PRED 1: C C ( C ) = C C N 1 C C C 2 ( C ) c 3 c c ( O ) c ( O ) c c 3 C C 1 C 2 C\n",
      "PRED SCORE: -1.5226\n",
      "\n",
      "BEST HYP:\n",
      "[-1.5226] ['C', 'C', '(', 'C', ')', '=', 'C', 'C', 'N', '1', 'C', 'C', 'C', '2', '(', 'C', ')', 'c', '3', 'c', 'c', '(', 'O', ')', 'c', '(', 'O', ')', 'c', 'c', '3', 'C', 'C', '1', 'C', '2', 'C']\n",
      "[-2.0030] ['C', 'C', '(', 'C', ')', '=', 'C', 'C', 'N', '1', 'C', 'C', 'C', '2', '(', 'C', ')', 'c', '3', 'c', 'c', '(', 'O', ')', 'c', 'c', 'c', '3', 'C', 'C', '1', 'C', '2', 'C']\n",
      "[-2.8990] ['C', 'O', 'c', '1', 'c', 'c', 'c', '2', 'c', '(', 'c', '1', ')', 'C', '1', '(', 'C', ')', 'C', 'C', 'N', '(', 'C', 'C', '=', 'C', '(', 'C', ')', 'C', ')', 'C', '(', 'C', '2', ')', 'C', '1', 'C']\n",
      "[-3.0935] ['C', 'C', '(', 'C', ')', '=', 'C', 'C', 'N', '1', 'C', 'C', 'C', '2', '(', 'C', ')', 'c', '3', 'c', '(', 'c', 'c', 'c', '(', 'O', ')', 'c', '3', 'O', ')', 'C', 'C', '1', 'C', '2', 'C']\n",
      "[-11.1125] ['C', 'O', 'c', '1', 'c', 'c', 'c', '2', 'c', '(', 'c', '1', ')', 'C', '1', '(', 'C', ')', 'C', 'C', 'N', '(', 'C', 'C', '=', 'C', '(', 'C', ')', 'C', ')', 'C', '(', 'C', '2', ')', 'C', '1']\n",
      "PRED AVG SCORE: -0.0412, PRED PPL: 1.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-seal@broadinstitut-41f01/.local/lib/python3.7/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n"
     ]
    }
   ],
   "source": [
    "df = process_dataset(df_smiles, 'smiles', 'binary_label', min_ph=14, max_ph=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14b711-5fe7-4037-b26a-a39cd4b2ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b6a77-13b5-4b8e-9ce0-ba1576c801fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
