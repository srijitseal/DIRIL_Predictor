{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465fa90-0581-4f3c-a405-06c0d1ba78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import ast  # Import the Abstract Syntax Trees (ast) module\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skactiveml.classifier import SklearnClassifier\n",
    "from skactiveml.regressor import NICKernelRegressor\n",
    "from skactiveml.pool import UncertaintySampling, ExpectedModelVarianceReduction\n",
    "from skactiveml.pool import RandomSampling\n",
    "from skactiveml.utils import unlabeled_indices, labeled_indices, MISSING_LABEL\n",
    "from skactiveml.visualization import plot_decision_boundary, plot_utilities\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "import warnings\n",
    "mlp.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from skactiveml.pool import UncertaintySampling\n",
    "from skactiveml.utils import unlabeled_indices, MISSING_LABEL\n",
    "from skactiveml.classifier import SklearnClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'n_jobs': [10],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "def generate_features(df, featurespace= \"mordred_descriptors\"):\n",
    "    \n",
    "    X = np.array(df[featurespace].tolist())\n",
    "    y = np.array(df['Label'].tolist())\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def datasplits(X, y):\n",
    "    \n",
    "    # Identify non-NaN indices\n",
    "    non_nan_indices = ~np.isnan(y)\n",
    "\n",
    "    # Split only the non-NaN parts into test and part of train\n",
    "    X_non_nan = X[non_nan_indices]\n",
    "    y_non_nan = y[non_nan_indices]\n",
    "    X_train_partial, X_test, y_train_partial, y_test = train_test_split(\n",
    "        X_non_nan, y_non_nan, test_size=0.25, random_state=24, stratify=y_non_nan\n",
    "    )\n",
    "\n",
    "    # Combine the non-selected non-NaN data back with NaN-containing rows for the full train set\n",
    "    # Identify indices for rows used in X_train_partial (inverse operation might be needed depending on how you track selected indices)\n",
    "    # This is a conceptual step; specifics depend on ensuring we don't double-count or omit any rows\n",
    "\n",
    "    # For simplicity, let's include all original data in X_train, then remove X_test entries\n",
    "    X_train = np.concatenate((X_train_partial, X[~non_nan_indices]), axis=0)\n",
    "    y_train = np.concatenate((y_train_partial, y[~non_nan_indices]), axis=0)\n",
    "\n",
    "    # Verifications\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    print(f\"Number of NaNs in y_test: {np.isnan(y_test).sum()}\")  # Should be 0\n",
    "    print(f\"Number of NaNs in y_train: {np.isnan(y_train).sum()}\")  # Original number minus the ones in y_test\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def initial_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    non_nan_indices_y_train = ~np.isnan(y_train)\n",
    "    # Getting unique values and their counts\n",
    "    unique_values, counts = np.unique(y_train[non_nan_indices_y_train], return_counts=True)\n",
    "    # Combining unique values and counts into a dictionary for a similar output to pandas.Series.value_counts()\n",
    "    value_counts = dict(zip(unique_values, counts))\n",
    "    print(\"Total data value counrs : \" , value_counts)\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    searcher = RandomizedSearchCV(clf, param_distributions, n_iter=10, scoring='balanced_accuracy', \n",
    "                                          cv=5, n_jobs =-1, random_state=42)\n",
    "    searcher.fit(X_train[non_nan_indices_y_train], y_train[non_nan_indices_y_train])\n",
    "\n",
    "    # Update clf to the best estimator\n",
    "    clf = SklearnClassifier(\n",
    "                searcher.best_estimator_,\n",
    "                classes=np.unique(y_test),\n",
    "                random_state=0\n",
    "            )\n",
    "\n",
    "    clf.fit(X_train[non_nan_indices_y_train], y_train[non_nan_indices_y_train])\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
    "\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_proba)  # Ensure y_test is appropriately encoded for binary classification\n",
    "\n",
    "    print(f'The balanced accuracy score is {balanced_accuracy}.')\n",
    "    print(f'The AUC score is {auc_score}.')\n",
    "    \n",
    "    return\n",
    "\n",
    "print(\"Reading data\")\n",
    "df = pd.read_csv(\"data/DIRIL_features_v2.csv.gz\", compression=\"gzip\")\n",
    "df['morgan_fingerprint'] = df['morgan_fingerprint'].apply(ast.literal_eval)\n",
    "df['mordred_descriptors'] = df['mordred_descriptors'].apply(ast.literal_eval)\n",
    "\n",
    "def active_learning(featurespace =\"mordred_descriptors\" ,n_cycles=1000):\n",
    "    \n",
    "    X,y = generate_features(df, featurespace= \"mordred_descriptors\")\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = datasplits(X, y)\n",
    "    \n",
    "\n",
    "    # Create classifier and query strategy.\n",
    "    clf = SklearnClassifier(\n",
    "        RandomForestClassifier(random_state=42, n_jobs=10),\n",
    "        classes=np.unique(y_test),\n",
    "        random_state=0\n",
    "        )\n",
    "\n",
    "    qs = UncertaintySampling(method='entropy')\n",
    "    #qs = RandomSampling()\n",
    "    \n",
    "    initial_model(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    auc_scores = []\n",
    "    sample_counts = []\n",
    "\n",
    "    non_nan_indices_y_train = ~np.isnan(y_train)\n",
    "    clf.fit(X_train[non_nan_indices_y_train], y_train[non_nan_indices_y_train])\n",
    "\n",
    "    for c in tqdm(range(n_cycles), desc='Processing cycles'):\n",
    "\n",
    "        # plotting\n",
    "        unlbld_idx = unlabeled_indices(y_train)\n",
    "        lbld_idx = labeled_indices(y_train)\n",
    "\n",
    "        if c%1==0:\n",
    "\n",
    "            # print(f'After {c} iterations:')\n",
    "\n",
    "            # Getting unique values and their counts\n",
    "            unique_values, counts = np.unique(y_train, return_counts=True)\n",
    "            # Combining unique values and counts into a dictionary for a similar output to pandas.Series.value_counts()\n",
    "            value_counts = dict(zip(unique_values, counts))\n",
    "\n",
    "            # print(\"Total labelled data : \" , len(lbld_idx))\n",
    "            # print(\"Total data value counrs : \" , value_counts)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_proba = clf.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
    "\n",
    "            balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "            auc_score = roc_auc_score(y_test, y_proba)  # Ensure y_test is appropriately encoded for binary classification\n",
    "\n",
    "            # print(f'After {c} iterations:')\n",
    "            # print(f'The balanced accuracy score is {balanced_accuracy}.')\n",
    "            # print(f'The AUC score is {auc_score}.')\n",
    "\n",
    "            accuracy_scores.append(balanced_accuracy)\n",
    "            auc_scores.append(auc_score)\n",
    "            sample_counts.append(len(lbld_idx))\n",
    "\n",
    "\n",
    "        query_idx = qs.query(X=X_train, y=y_train, clf=clf, batch_size=1)\n",
    "        #query_idx = qs.query(X=X_train, y=y_train)\n",
    "        y_train[query_idx] = clf.predict(X_train[query_idx])\n",
    "\n",
    "        if c%1==0:\n",
    "\n",
    "            # Optimize hyperparameters using RandomizedSearchCV\n",
    "            clf = RandomForestClassifier(random_state=42)\n",
    "            non_nan_indices_y_train = ~np.isnan(y_train)\n",
    "            searcher = RandomizedSearchCV(clf, param_distributions, n_iter=10, scoring='balanced_accuracy', \n",
    "                                          cv=5, n_jobs =-1, random_state=42)\n",
    "            searcher.fit(X_train[non_nan_indices_y_train], y_train[non_nan_indices_y_train])\n",
    "\n",
    "            # Update clf to the best estimator\n",
    "            clf = SklearnClassifier(\n",
    "                searcher.best_estimator_,\n",
    "                classes=np.unique(y_test),\n",
    "                random_state=0\n",
    "            )\n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(sample_counts, accuracy_scores, marker='o', label='Balanced Accuracy')\n",
    "    plt.xlabel('Number of Labeled Samples + Metabolites')\n",
    "    plt.ylabel('Balanced Accuracy Score')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'./results_plots/accuracy_vs_samples{featurespace}.png') \n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(sample_counts, auc_scores, marker='o', label='Balanced Accuracy')\n",
    "    plt.xlabel('Number of Labeled Samples + Metabolites')\n",
    "    plt.ylabel('AUCROC')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'./results_plots/auc_vs_samples{featurespace}.png') \n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "print(\"Runnin Models\")\n",
    "active_learning(featurespace =\"mordred_descriptors\", n_cycles=1000)\n",
    "active_learning(featurespace =\"morgan_fingerprint\", n_cycles=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
